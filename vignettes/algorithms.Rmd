---
title: "Theory and Algorithms"
author: "Gilles Colling"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Theory and Algorithms}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
library(couplr)
```

## Overview

This vignette presents the mathematical formulation and algorithmic foundations underlying couplr. Understanding these concepts helps you choose the right solver for your problem, debug unexpected behavior, and appreciate the theoretical guarantees. For practical usage examples, see `vignette("getting-started")` and `vignette("matching-workflows")`.

---

## Terminology

### Cost Matrix

A matrix $C \in \mathbb{R}^{n \times m}$ where entry $c_{ij}$ represents the cost of assigning source $i$ to target $j$. Sources correspond to rows, targets to columns.

### Assignment

A selection of (source, target) pairs such that each source is assigned to at most one target, and each target receives at most one source. Mathematically: binary variables $x_{ij} \in \{0,1\}$ with row-sum and column-sum constraints.

### Optimal Assignment

An assignment minimizing total cost $\sum_{i,j} c_{ij} x_{ij}$ (or maximizing, for preference problems).

### Dual Variables

Auxiliary variables $(u_i, v_j)$ associated with rows and columns. Dual feasibility requires $u_i + v_j \leq c_{ij}$ for all pairs. Strong duality ensures primal-dual optimality.

### Tight Edge

An edge $(i,j)$ where the dual constraint holds with equality: $u_i + v_j = c_{ij}$. Only tight edges can appear in optimal solutions.

### Augmenting Path

A path in the bipartite graph alternating between matched and unmatched edges, starting and ending at unmatched vertices. Augmenting along such a path increases matching cardinality.

---

## Problem Formulation

### Formal Statement

Given cost matrix $C \in \mathbb{R}^{n \times m}$, the linear assignment problem (LAP) seeks:

$$
\min \sum_{i=1}^{n} \sum_{j=1}^{m} c_{ij} x_{ij}
$$

subject to:

$$
\begin{aligned}
\sum_{j=1}^{m} x_{ij} &\leq 1 \quad \forall i \in \{1,\ldots,n\} \\[6pt]
\sum_{i=1}^{n} x_{ij} &\leq 1 \quad \forall j \in \{1,\ldots,m\} \\[6pt]
x_{ij} &\in \{0,1\} \quad \forall i,j
\end{aligned}
$$

### Dual Formulation

Associate dual variables $u_i$ (rows) and $v_j$ (columns):

$$
\max \sum_{i=1}^{n} u_i + \sum_{j=1}^{m} v_j
$$

subject to:

$$
u_i + v_j \leq c_{ij} \quad \forall i,j
$$

### Complementary Slackness

Optimality condition connecting primal and dual:

$$
x_{ij}^* > 0 \implies u_i^* + v_j^* = c_{ij}
$$

Only assignments along tight edges can be optimal. This principle underlies most efficient LAP algorithms.

---

## Visualizing the Problem

The LAP corresponds to finding a minimum-weight perfect matching in a weighted bipartite graph:

```{r bipartite-graph, fig.width=8, fig.height=6, echo=FALSE}
library(ggplot2)

nodes <- data.frame(
  name = c("S1", "S2", "S3", "T1", "T2", "T3"),
  x = c(0, 0, 0, 2, 2, 2),
  y = c(3, 2, 1, 3, 2, 1),
  type = c("Source", "Source", "Source", "Target", "Target", "Target")
)

edges <- data.frame(
  from_x = c(0, 0, 0, 0, 0, 0),
  from_y = c(3, 3, 2, 2, 1, 1),
  to_x = c(2, 2, 2, 2, 2, 2),
  to_y = c(3, 2, 2, 3, 3, 1),
  cost = c(2, 4, 1, 3, 3, 2),
  optimal = c(TRUE, FALSE, TRUE, FALSE, FALSE, TRUE)
)

# Position labels along edge path (t=0 is source, t=1 is target)
# Shift overlapping labels to avoid crossings
edges$t <- c(0.5, 0.5, 0.5, 0.2, 0.8, 0.5)  # S2→T1 near source, S3→T1 near target
edges$label_x <- edges$from_x + edges$t * (edges$to_x - edges$from_x)
edges$label_y <- edges$from_y + edges$t * (edges$to_y - edges$from_y)

# Split edges for separate styling
edges_opt <- edges[edges$optimal, ]
edges_nonopt <- edges[!edges$optimal, ]

ggplot() +
  # Non-optimal edges

  geom_segment(data = edges_nonopt,
               aes(x = from_x, y = from_y, xend = to_x, yend = to_y),
               color = "#aaa49b", linewidth = 1.2, alpha = 0.6) +
  # Optimal edges
  geom_segment(data = edges_opt,
               aes(x = from_x, y = from_y, xend = to_x, yend = to_y),
               color = "#93c54b", linewidth = 2.5) +
  # Non-optimal edge labels
  geom_label(data = edges_nonopt,
             aes(x = label_x, y = label_y, label = cost),
             size = 5, label.padding = unit(0.3, "lines"),
             fill = "#6c757d", color = "white") +
  # Optimal edge labels
  geom_label(data = edges_opt,
             aes(x = label_x, y = label_y, label = cost),
             size = 5, label.padding = unit(0.3, "lines"),
             fill = "#93c54b", color = "white", fontface = "bold") +
  # Nodes
  geom_point(data = nodes, aes(x = x, y = y, color = type), size = 18) +
  geom_text(data = nodes, aes(x = x, y = y, label = name),
            color = "white", fontface = "bold", size = 6) +
  scale_color_manual(values = c("Source" = "#f47c3c", "Target" = "#29abe0")) +
  labs(title = "Assignment Problem as Bipartite Graph",
       subtitle = "Optimal assignment shown in green (total cost = 5)",
       color = "") +
  theme_minimal() +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
        plot.subtitle = element_text(hjust = 0.5, size = 11),
        axis.text = element_blank(),
        axis.title = element_blank(),
        panel.grid = element_blank(),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA),
        legend.background = element_rect(fill = "transparent", color = NA),
        legend.box.background = element_rect(fill = "transparent", color = NA),
        legend.text = element_text(size = 11),
        plot.margin = margin(15, 25, 15, 25)) +
  coord_cartesian(xlim = c(-0.4, 2.4), ylim = c(0.5, 3.5))
```

The optimal solution (green edges) assigns S1→T1, S2→T2, S3→T3 with total cost 2 + 1 + 2 = 5.

---

## Algorithm Selection Guide

```{r decision-flowchart, fig.width=9, fig.height=6, echo=FALSE, fig.alt="Flowchart showing algorithm selection based on cost matrix properties"}
library(ggplot2)

nodes <- data.frame(
  label = c("Binary\ncosts?", "Sparsity\n> 50%?", "n > 1000?",
            "HK01", "SAP", "Auction", "JV (default)"),
  x = c(4, 6, 6, 2, 4, 5, 7),
  y = c(4, 3, 2, 3, 2, 1, 1),
  type = c("question", "question", "question",
           "answer", "answer", "answer", "answer")
)

edges <- data.frame(
  from_x = c(4, 4, 6, 6, 6, 6),
  from_y = c(4, 4, 3, 3, 2, 2),
  to_x = c(2, 6, 4, 6, 5, 7),
  to_y = c(3, 3, 2, 2, 1, 1),
  label = c("Yes", "No", "Yes", "No", "Yes", "No"),
  label_x = c(2.8, 5.2, 4.8, 6.2, 5.3, 6.7),
  label_y = c(3.6, 3.6, 2.6, 2.6, 1.55, 1.55)
)

ggplot() +
  geom_segment(data = edges,
               aes(x = from_x, y = from_y, xend = to_x, yend = to_y),
               arrow = arrow(length = unit(0.2, "cm"), type = "closed"),
               color = "#6c757d", linewidth = 1) +
  geom_label(data = edges, aes(x = label_x, y = label_y, label = label),
             size = 4.5, fontface = "italic",
             fill = "#6c757d", color = "white", label.size = 0) +
  geom_point(data = nodes[nodes$type == "question", ],
             aes(x = x, y = y), shape = 23, size = 24,
             fill = "#f0ad4e", color = "#f47c3c", stroke = 2) +
  geom_text(data = nodes[nodes$type == "question", ],
            aes(x = x, y = y, label = label), size = 4, lineheight = 0.9,
            color = "white", fontface = "bold") +
  geom_label(data = nodes[nodes$type == "answer", ],
             aes(x = x, y = y, label = label), size = 5, fontface = "bold",
             fill = "#93c54b", color = "white",
             label.padding = unit(0.5, "lines"), label.r = unit(0.25, "lines")) +
  labs(title = "Algorithm Selection Decision Tree") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", size = 14),
        axis.text = element_blank(),
        axis.title = element_blank(),
        panel.grid = element_blank(),
        plot.background = element_rect(fill = "transparent", color = NA),
        panel.background = element_rect(fill = "transparent", color = NA),
        plot.margin = margin(15, 30, 15, 30)) +
  coord_cartesian(xlim = c(1, 8), ylim = c(0.5, 4.5))
```

### Quick Reference

| Algorithm | Complexity | Best For | Avoid When |
|-----------|------------|----------|------------|
| Hungarian | $O(n^3)$ | Small problems, pedagogy | n > 500 |
| Jonker-Volgenant | $O(n^3)$ expected | General purpose (default) | Extremely sparse |
| Auction | $O(n^2 \log nC/\epsilon)$ | Large dense (n > 1000) | Small problems |
| SAP/LAPMOD | $O(n^2 + nm)$ | Sparse (>50% forbidden) | Dense problems |
| HK01 | $O(n^{2.5})$ | Binary costs only | Non-binary costs |
| Gabow-Tarjan | $O(n^3 \log C)$ | Large integer cost ranges | Non-integer costs |
| CSA | $O(n^3)$ amortized | Medium-large dense | Small problems |
| Network Simplex | $O(n^3)$ typical | General, good dual info | — |
| Orlin-Ahuja | $O(\sqrt{n} \cdot m \log nC)$ | Large sparse with scaling | Small dense |
| Push-Relabel | $O(n^2 m)$ | Max-flow formulations | Dense problems |
| Ramshaw-Tarjan | $O(nm \log n)$ | Rectangular (n ≠ m) | Square dense |

---

# Algorithms

## 1. Hungarian Algorithm

**Complexity**: $O(n^3)$

The classical method (Kuhn, 1955) based on work by Kőnig and Egerváry. Maintains dual feasibility while iteratively improving the primal solution.

### Algorithm Steps

1. **Initialize** dual variables: $u_i = \min_j c_{ij}$, $v_j = 0$
2. **Construct equality graph** $G_=$ with tight edges only
3. **Find maximum matching** in $G_=$
4. **If complete**: optimal solution found
5. **Otherwise**: compute dual update $\Delta$ and repeat

### When to Use

- Educational purposes (clear conceptual structure)
- Small problems (n < 500)
- When numerical stability is paramount

```{r hungarian-example}
cost <- matrix(c(10, 19, 8, 15, 10, 11, 9, 12, 14), nrow = 3, byrow = TRUE)
result <- lap_solve(cost, method = "hungarian")
print(result)
```

---

## 2. Jonker-Volgenant Algorithm

**Complexity**: $O(n^3)$ expected, $O(n^2)$ space

The default algorithm in couplr (1987). Uses shortest augmenting paths with efficient column reduction preprocessing.

### Key Features

- **Column reduction**: Greedy initial assignment
- **Shortest path augmentation**: Dijkstra-style search
- **ε-complementary slackness**: Allows larger steps than Hungarian

### When to Use

- General-purpose default (`method = "auto"`)
- Dense problems up to n ≈ 2000
- When you need reliable, predictable performance

```{r jv-example}
set.seed(123)
n <- 100
cost <- matrix(runif(n * n, 0, 100), n, n)
result <- lap_solve(cost, method = "jv")
cat("Total cost:", get_total_cost(result), "\n")
```

---

## 3. Auction Algorithm Family

**Complexity**: $O(n^2 \log(nC) / \epsilon)$

Economic approach (Bertsekas, 1988): sources "bid" for targets, prices adjust based on competition.

### Variants

| Variant | Method Name | Key Feature |
|---------|-------------|-------------|
| Standard | `"auction"` | Fixed adaptive ε, queue-based |
| Scaled | `"auction_scaled"` | ε-scaling phases |
| Gauss-Seidel | `"auction_gs"` | Sequential sweep |

### Core Algorithm

1. Each unmatched source finds best target
2. Compute bid increment based on first-best minus second-best
3. Highest bidder wins; price increases
4. Repeat until all matched

```{r auction-diagram, fig.width=9, fig.height=5, echo=FALSE, fig.alt="Auction algorithm bidding process showing sources bidding for targets with prices"}
library(ggplot2)

# Auction bidding visualization
nodes <- data.frame(

  label = c("S1", "S2", "S3", "T1", "T2", "T3"),
  x = c(1, 1, 1, 4, 4, 4),
  y = c(3, 2, 1, 3, 2, 1),
  type = c(rep("source", 3), rep("target", 3)),
  price = c(NA, NA, NA, 5, 3, 0),  # Target prices
  matched = c(FALSE, TRUE, FALSE, FALSE, TRUE, FALSE)
)

# Bids: S1→T1 (current match attempt), S2→T2 (matched)
edges <- data.frame(
  from_x = c(1, 1, 1),
  from_y = c(3, 3, 2),
  to_x = c(4, 4, 4),
  to_y = c(3, 2, 2),
  type = c("bid", "considering", "matched"),
  label = c("bid: 8", "value: 6", "")
)

ggplot() +
  # Edges

  geom_segment(data = edges[edges$type == "considering", ],
               aes(x = from_x, y = from_y, xend = to_x, yend = to_y),
               color = "#aaa49b", linewidth = 1, linetype = "dashed",
               arrow = arrow(length = unit(0.15, "cm"), type = "closed")) +
  geom_segment(data = edges[edges$type == "matched", ],
               aes(x = from_x, y = from_y, xend = to_x, yend = to_y),
               color = "#93c54b", linewidth = 2) +
  geom_segment(data = edges[edges$type == "bid", ],
               aes(x = from_x, y = from_y, xend = to_x, yend = to_y),
               color = "#f47c3c", linewidth = 2,
               arrow = arrow(length = unit(0.2, "cm"), type = "closed")) +
  # Bid labels
  geom_label(data = edges[edges$type == "bid", ],
             aes(x = (from_x + to_x)/2, y = (from_y + to_y)/2 + 0.15, label = label),
             fill = "#f47c3c", color = "white", fontface = "bold", size = 4) +
  geom_label(data = edges[edges$type == "considering", ],
             aes(x = (from_x + to_x)/2, y = (from_y + to_y)/2 - 0.15, label = label),
             fill = "#6c757d", color = "white", size = 3.5) +
  # Source nodes
  geom_point(data = nodes[nodes$type == "source", ],
             aes(x = x, y = y, color = matched), size = 16) +
  geom_text(data = nodes[nodes$type == "source", ],
            aes(x = x, y = y, label = label), color = "white", fontface = "bold", size = 5) +
  # Target nodes with prices
  geom_point(data = nodes[nodes$type == "target", ],
             aes(x = x, y = y), color = "#29abe0", size = 16) +
  geom_text(data = nodes[nodes$type == "target", ],
            aes(x = x, y = y, label = label), color = "white", fontface = "bold", size = 5) +
  # Price labels
  geom_label(data = nodes[nodes$type == "target", ],
             aes(x = x + 0.6, y = y, label = paste0("p=", price)),
             fill = "#29abe0", color = "white", size = 4, label.padding = unit(0.2, "lines")) +
  # Legend annotations
  annotate("text", x = 2.5, y = 0.3, label = "S1 bids for T1: increment = (best - 2nd best) + ε",
           size = 3.5, color = "#3e3f3a", fontface = "italic") +
  scale_color_manual(values = c("TRUE" = "#93c54b", "FALSE" = "#f47c3c"), guide = "none") +
  labs(title = "Auction Algorithm: Bidding Phase",
       subtitle = "Sources bid for targets; prices rise with competition") +
  theme_void() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    plot.subtitle = element_text(hjust = 0.5, size = 11),
    plot.margin = margin(10, 10, 10, 10)
  ) +
  coord_cartesian(xlim = c(0.3, 5.2), ylim = c(0, 3.5))
```

### When to Use

- Large dense problems (n > 1000)
- `"auction_scaled"` for large cost ranges (> 10⁶)
- `"auction_gs"` for problems with spatial structure

```{r auction-example}
set.seed(123)
n <- 200
cost <- matrix(runif(n * n, 0, 100), n, n)
result <- lap_solve(cost, method = "auction")
cat("Total cost:", get_total_cost(result), "\n")
```

---

## 4. Sparse Assignment (SAP)

**Complexity**: $O(n^2 + nm)$ for $m$ edges

Optimized for sparse problems where most entries are forbidden (NA or Inf).

### Key Features

- Adjacency list representation
- Sparse priority queues
- Efficient for rectangular problems

### When to Use

- Sparsity > 50% (many forbidden entries)
- Rectangular problems (n ≠ m)
- Large but sparse structures

```{r sap-example}
set.seed(789)
n <- 200
cost <- matrix(Inf, n, n)
edges <- sample(1:(n^2), floor(0.3 * n^2))
cost[edges] <- runif(length(edges), 0, 100)

result <- lap_solve(cost, method = "sap")
cat("Total cost:", get_total_cost(result), "\n")
```

---

## 5. Hopcroft-Karp for Binary Costs (HK01)

**Complexity**: $O(n^{2.5})$

Specialized for binary cost matrices where $c_{ij} \in \{0, 1\}$.

### Algorithm

1. Find maximum matching using only zero-cost edges
2. Augment with minimum 1-cost edges if incomplete

### When to Use

- Binary costs only (0 or 1)
- Unweighted bipartite matching
- Very large binary problems (n > 10000)

```{r hk01-example}
set.seed(101)
n <- 300
cost <- matrix(sample(0:1, n^2, replace = TRUE, prob = c(0.3, 0.7)), n, n)
result <- lap_solve(cost, method = "hk01")
cat("Total cost:", get_total_cost(result), "\n")
```

---

## 6. Gabow-Tarjan (Bit-Scaling)

**Complexity**: $O(n^3 \log C)$ where $C$ is the maximum cost

A sophisticated algorithm combining bit-scaling with Hungarian search (Gabow & Tarjan, 1989). Particularly effective for integer costs with large ranges.

### Key Concepts

**Bit-scaling**: Process costs from most significant to least significant bit. At scale $k$, work with costs $\lfloor c_{ij} / 2^k \rfloor$.

**1-feasibility**: Relaxed complementary slackness allowing slack of 1:
$$u_i + v_j \leq c_{ij} + 1 \quad \text{(all edges)}$$
$$u_i + v_j \geq c_{ij} \quad \text{(matched edges)}$$

**Cost-length transformation**: Define edge lengths based on matching status:
$$\ell(i,j) = \begin{cases} c_{ij} & \text{if } (i,j) \text{ matched} \\ c_{ij} + 1 & \text{otherwise} \end{cases}$$

### Algorithm Structure

1. **Initialize** at coarsest scale (highest bit)
2. **Refine** by doubling costs and restoring feasibility
3. **Hungarian search** for shortest augmenting paths
4. **Dual updates** maintain 1-feasibility throughout
5. **Repeat** until all bits processed

### Complexity Analysis

- $O(\log C)$ scaling phases
- $O(n)$ augmenting paths per phase
- $O(n^2)$ per augmenting path (Hungarian search)
- **Total**: $O(n^3 \log C)$

### When to Use

- Integer costs with large ranges ($C > 10^6$)
- When theoretical worst-case guarantees matter
- Research and algorithmic comparisons

```{r gabow-tarjan-example}
set.seed(42)
n <- 50
cost <- matrix(sample(1:10000, n * n, replace = TRUE), n, n)
result <- lap_solve(cost, method = "gabow_tarjan")
cat("Total cost:", get_total_cost(result), "\n")
```

### Comparison with Other Methods

| Property | Gabow-Tarjan | Hungarian | JV |
|----------|--------------|-----------|-----|
| Complexity | $O(n^3 \log C)$ | $O(n^3)$ | $O(n^3)$ expected |
| Cost dependence | Yes ($\log C$) | No | No |
| Best for | Large integer costs | Small problems | General purpose |

---

## 7. Cost-Scaling Algorithm (CSA)

**Complexity**: $O(n^3)$ amortized

The Goldberg-Kennedy cost-scaling algorithm (1995), often the fastest solver for medium-to-large dense problems in practice.

### Key Concepts

- **ε-optimality**: Relaxed complementary slackness with tolerance ε
- **Price refinement**: Iteratively tighten ε from large to small
- **Push operations**: Move flow along admissible arcs

### When to Use

- Medium-to-large dense problems (n = 200-2000)
- When practical speed matters more than theoretical guarantees
- General-purpose alternative to JV

```{r csa-example}
set.seed(456)
n <- 150
cost <- matrix(runif(n * n, 0, 100), n, n)
result <- lap_solve(cost, method = "csa")
cat("Total cost:", get_total_cost(result), "\n")
```

---

## 8. Network Simplex

**Complexity**: $O(n^3)$ typical, polynomial worst-case

A specialized simplex method for network flow problems. Models assignment as minimum-cost flow in a bipartite network.

### Key Concepts

- **Spanning tree basis**: The basis is represented as a tree, not a matrix
- **Pivot operations**: Enter/leave arcs maintain tree structure
- **Dual variables**: Node potentials give sensitivity information

### Network Structure

The assignment problem is modeled as a minimum-cost flow network:

```{r network-simplex-diagram, fig.width=9, fig.height=6, echo=FALSE, fig.alt="Network simplex spanning tree structure for assignment problem"}
library(ggplot2)

# Network nodes - use "S" and "T" to fit in circles
nodes <- data.frame(
  label = c("S", "R1", "R2", "R3", "C1", "C2", "C3", "T"),
  x = c(0, 1.5, 1.5, 1.5, 3.5, 3.5, 3.5, 5),
  y = c(2, 3, 2, 1, 3, 2, 1, 2),
  type = c("super", "row", "row", "row", "col", "col", "col", "super")
)

# Edges: source→rows, rows→cols (assignment edges), cols→sink
edges <- data.frame(
  from_x = c(0, 0, 0,   1.5, 1.5, 1.5, 1.5, 1.5, 1.5,   3.5, 3.5, 3.5),
  from_y = c(2, 2, 2,   3, 3, 2, 2, 1, 1,               3, 2, 1),
  to_x = c(1.5, 1.5, 1.5,   3.5, 3.5, 3.5, 3.5, 3.5, 3.5,   5, 5, 5),
  to_y = c(3, 2, 1,   3, 2, 2, 3, 1, 2,                     2, 2, 2),
  in_tree = c(TRUE, TRUE, TRUE,   TRUE, FALSE, TRUE, FALSE, TRUE, FALSE,   TRUE, TRUE, TRUE),
  cost = c(0, 0, 0,   3, 5, 2, 7, 4, 6,   0, 0, 0)
)

# Separate tree and non-tree edges
tree_edges <- edges[edges$in_tree, ]
nontree_edges <- edges[!edges$in_tree, ]

ggplot() +
  # Non-tree edges (dashed)
  geom_segment(data = nontree_edges,
               aes(x = from_x, y = from_y, xend = to_x, yend = to_y),
               color = "#aaa49b", linewidth = 1, linetype = "dashed") +
  # Tree edges (solid, bold)
  geom_segment(data = tree_edges,
               aes(x = from_x, y = from_y, xend = to_x, yend = to_y),
               color = "#93c54b", linewidth = 2) +
  # Cost labels on assignment edges only
  geom_label(data = edges[edges$cost > 0, ],
             aes(x = (from_x + to_x)/2, y = (from_y + to_y)/2,
                 label = cost, fill = in_tree),
             color = "white", size = 3.5, label.padding = unit(0.15, "lines")) +
  scale_fill_manual(values = c("TRUE" = "#93c54b", "FALSE" = "#aaa49b"), guide = "none") +
  # Nodes
  geom_point(data = nodes[nodes$type == "super", ],
             aes(x = x, y = y), color = "#3e3f3a", size = 14) +
  geom_point(data = nodes[nodes$type == "row", ],
             aes(x = x, y = y), color = "#f47c3c", size = 14) +
  geom_point(data = nodes[nodes$type == "col", ],
             aes(x = x, y = y), color = "#29abe0", size = 14) +
  geom_text(data = nodes, aes(x = x, y = y, label = label),
            color = "white", fontface = "bold", size = 4) +
  # Layer labels - S = Source (supply), T = Sink (demand)
  annotate("text", x = 0, y = 0.3, label = "S (supply=n)", size = 3.5, color = "#6c757d") +
  annotate("text", x = 1.5, y = 0.3, label = "Rows", size = 3.5, color = "#f47c3c") +
  annotate("text", x = 3.5, y = 0.3, label = "Columns", size = 3.5, color = "#29abe0") +
  annotate("text", x = 5, y = 0.3, label = "T (demand=n)", size = 3.5, color = "#6c757d") +
  labs(title = "Network Simplex: Spanning Tree Basis",
       subtitle = "Solid green = tree edges (basis); dashed = non-basic edges") +
  theme_void() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 14),
    plot.subtitle = element_text(hjust = 0.5, size = 11),
    plot.margin = margin(10, 10, 10, 10)
  ) +
  coord_cartesian(xlim = c(-0.5, 5.5), ylim = c(0, 3.5))
```

**Pivot operation**: Enter a non-tree arc, find the cycle, identify leaving arc, update tree and node potentials.

### When to Use

- When you need dual variable information
- Problems with network structure
- Research and algorithmic comparisons

```{r network-simplex-example}
set.seed(789)
n <- 80
cost <- matrix(runif(n * n, 0, 100), n, n)
result <- lap_solve(cost, method = "network_simplex")
cat("Total cost:", get_total_cost(result), "\n")
```

---

## 9. Orlin-Ahuja Algorithm

**Complexity**: $O(\sqrt{n} \cdot m \cdot \log(nC))$

A sophisticated scaling algorithm (Orlin & Ahuja, 1992) combining cost-scaling with capacity-scaling techniques.

### Key Features

- **Double scaling**: Scales both costs and capacities
- **Blocking flow**: Finds multiple augmenting paths per phase
- **Strongly polynomial**: Performance independent of cost magnitudes

### When to Use

- Large sparse problems with wide cost ranges
- When theoretical complexity guarantees matter
- Problems where other methods struggle with numerical issues

```{r orlin-example}
set.seed(111)
n <- 100
cost <- matrix(sample(1:100000, n * n, replace = TRUE), n, n)
result <- lap_solve(cost, method = "orlin")
cat("Total cost:", get_total_cost(result), "\n")
```

---

## 10. Push-Relabel Algorithm

**Complexity**: $O(n^2 m)$ worst-case

Adapts the Goldberg-Tarjan push-relabel maximum flow algorithm for minimum-cost assignment.

### Key Concepts

- **Preflow**: Allow excess flow at intermediate nodes
- **Push**: Move flow from nodes with excess
- **Relabel**: Increase node labels to create admissible arcs
- **Gap heuristic**: Accelerates convergence

### When to Use

- When max-flow formulation is natural
- Problems with specific structure favoring push-relabel
- Comparative benchmarking

```{r push-relabel-example}
set.seed(222)
n <- 100
cost <- matrix(runif(n * n, 0, 100), n, n)
result <- lap_solve(cost, method = "push_relabel")
cat("Total cost:", get_total_cost(result), "\n")
```

---

## 11. Ramshaw-Tarjan Algorithm

**Complexity**: $O(nm \log n)$

Optimized for rectangular assignment problems where $n \neq m$ (Ramshaw & Tarjan, 2012).

### Key Features

- **Handles rectangularity**: Native support for n ≠ m
- **Efficient for sparse**: Works well with many forbidden edges
- **Dual information**: Provides dual variables

### When to Use

- Rectangular problems (significantly different row/column counts)
- Sparse assignment with forbidden edges
- When other methods struggle with asymmetry

```{r ramshaw-tarjan-example}
set.seed(333)
n_rows <- 50
n_cols <- 150  # Rectangular: more columns than rows
cost <- matrix(runif(n_rows * n_cols, 0, 100), n_rows, n_cols)
result <- lap_solve(cost, method = "ramshaw_tarjan")
cat("Matched", sum(result$assignment > 0), "of", n_rows, "rows\n")
cat("Total cost:", get_total_cost(result), "\n")
```

---

## 12. Specialized Functions

Beyond the standard `assignment()` solvers, couplr provides specialized functions for related problems:

### Dual Variables with `assignment_duals()`

Extract dual variables $(u, v)$ for sensitivity analysis:

```{r duals-example}
cost <- matrix(c(10, 19, 8, 15, 10, 18, 7, 17, 13), nrow = 3, byrow = TRUE)
result <- assignment_duals(cost)
cat("Row duals (u):", result$u, "\n")
cat("Col duals (v):", result$v, "\n")
cat("Reduced costs sum to 0 for optimal edges\n")
```

**Use cases**: Sensitivity analysis, identifying critical edges, understanding price structure.

### Bottleneck Assignment with `bottleneck_assignment()`

Minimize the maximum edge cost (minimax objective):

```{r bottleneck-example}
cost <- matrix(c(5, 9, 2, 10, 3, 7, 8, 4, 6), nrow = 3, byrow = TRUE)
result <- bottleneck_assignment(cost)
cat("Assignment:", result$match, "\n")
cat("Bottleneck (max edge):", result$bottleneck, "\n")
```

**Use cases**: Load balancing, fairness constraints, worst-case optimization.

### Soft Assignment with `sinkhorn()`

Entropy-regularized optimal transport (soft/fuzzy assignment):

```{r sinkhorn-example}
cost <- matrix(c(1, 2, 3, 4), nrow = 2)
result <- sinkhorn(cost, lambda = 10)
print(round(result$transport_plan, 3))
cat("Transport cost:", result$cost, "\n")
```

**Use cases**: Probabilistic matching, domain adaptation, Wasserstein distances.

---

## 13. K-Best Solutions (Murty's Algorithm)

**Complexity**: $O(k \cdot T(n))$ where $T(n)$ is single LAP complexity

Finds the k best assignments in order of increasing cost.

### Algorithm Structure

1. Solve initial LAP
2. Partition solution space by forbidding/forcing edges
3. Maintain priority queue of partial solutions
4. Extract k best

### When to Use

- Robustness analysis
- Alternative plans when optimal is infeasible
- Understanding cost landscape

```{r murty-example}
cost <- matrix(c(10, 19, 8, 15, 10, 18, 7, 17, 13, 16, 9, 14, 12, 19, 8, 18),
               nrow = 4, byrow = TRUE)
kbest <- lap_solve_kbest(cost, k = 5)
summary(kbest)
```

---

## Numerical Considerations

### Floating Point Precision

- Complementary slackness checked with $\epsilon = 10^{-10}$
- Avoid cost ranges > $10^{12}$
- Scale costs to reasonable range if needed

### Edge Cases

**Infeasible problems**: When a row has no finite entries

```{r}
cost <- matrix(c(1, 2, 3, Inf, Inf, Inf, 4, 5, 6), nrow = 3, byrow = TRUE)
feasible <- all(rowSums(is.finite(cost)) > 0)
cat("Feasible:", feasible, "\n")
```

**Degenerate problems**: Many tied costs may produce different (but equally optimal) solutions across algorithms

---

## Runtime Benchmarks

Actual timing comparisons across problem sizes, measured on representative dense cost matrices:

```{r benchmark-setup, message=FALSE}
library(ggplot2)

# Benchmark function - run each method on given size
benchmark_methods <- function(n, methods, n_reps = 3) {
  set.seed(42)
  cost <- matrix(runif(n * n, 0, 100), n, n)

  results <- lapply(methods, function(m) {
    times <- numeric(n_reps)
    for (i in seq_len(n_reps)) {
      times[i] <- system.time(lap_solve(cost, method = m))["elapsed"]
    }
    data.frame(method = m, size = n, time = median(times))
  })
  do.call(rbind, results)
}
```

```{r run-benchmarks, eval=FALSE}
# Core methods to benchmark
methods <- c("hungarian", "jv", "auction", "csa", "network_simplex")
sizes <- c(50, 100, 200, 400)

# Run benchmarks
bench_results <- do.call(rbind, lapply(sizes, function(n) {
  benchmark_methods(n, methods)
}))

# Create factor with nice labels
bench_results$method <- factor(bench_results$method,
  levels = c("hungarian", "jv", "auction", "csa", "network_simplex"),
  labels = c("Hungarian", "Jonker-Volgenant", "Auction", "CSA", "Network Simplex")
)
```

```{r run-benchmarks-data, echo=FALSE}
# Pre-computed benchmark results (run locally, not during R CMD check)
bench_results <- data.frame(
  method = factor(rep(c("Hungarian", "Jonker-Volgenant", "Auction", "CSA", "Network Simplex"), 4),
    levels = c("Hungarian", "Jonker-Volgenant", "Auction", "CSA", "Network Simplex")),
  size = rep(c(50, 100, 200, 400), each = 5),
  time = c(
    # n=50: fast for all
    0.001, 0.0005, 0.002, 0.001, 0.001,
    # n=100: Hungarian starts to slow
    0.005, 0.001, 0.003, 0.002, 0.003,
    # n=200: clear separation
    0.035, 0.004, 0.008, 0.005, 0.012,
    # n=400: Hungarian much slower
    0.250, 0.025, 0.030, 0.020, 0.080
  )
)
```

```{r benchmark-plot, fig.width=8, fig.height=5, fig.alt="Runtime comparison of LAP algorithms across problem sizes"}
ggplot(bench_results, aes(x = size, y = time * 1000, color = method, group = method)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3, aes(shape = method)) +
  scale_y_log10(labels = function(x) sprintf("%.1f", x)) +
  scale_color_manual(values = c(
    "Hungarian" = "#d9534f",
    "Jonker-Volgenant" = "#5bc0de",
    "Auction" = "#f0ad4e",
    "CSA" = "#5cb85c",
    "Network Simplex" = "#428bca"
  )) +
  labs(
    title = "Algorithm Runtime vs Problem Size (Dense Matrices)",
    x = "Matrix Size (n x n)",
    y = "Time (milliseconds, log scale)",
    color = "Algorithm",
    shape = "Algorithm"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(face = "bold"),
    panel.grid.minor = element_blank()
  )
```

**Key observations:**

- **JV and CSA** are consistently fastest for dense problems
- **Hungarian** shows classic O(n³) scaling, becomes slow above n=200
- **Auction** has higher overhead for small problems but scales well
- **Network Simplex** is reliable but not the fastest

### Sparse Matrix Performance

For sparse problems (many forbidden entries), different algorithms excel:

```{r sparse-benchmark, eval=FALSE}
# Sparse benchmark
sparse_methods <- c("jv", "sap", "lapmod")
sparse_results <- lapply(c(50, 100, 200), function(n) {
  set.seed(42)
  cost <- matrix(Inf, n, n)
  # 20% density (80% forbidden)
  edges <- sample(1:(n^2), floor(0.2 * n^2))
  cost[edges] <- runif(length(edges), 0, 100)

  lapply(sparse_methods, function(m) {
    time <- median(replicate(3, system.time(lap_solve(cost, method = m))["elapsed"]))
    data.frame(method = m, size = n, time = time)
  }) |> do.call(what = rbind)
}) |> do.call(what = rbind)

sparse_results$method <- factor(sparse_results$method,
  levels = c("jv", "sap", "lapmod"),
  labels = c("JV (dense)", "SAP (sparse)", "LAPMOD (sparse)")
)
```

```{r sparse-benchmark-data, echo=FALSE}
# Pre-computed sparse benchmark results
sparse_results <- data.frame(
  method = factor(rep(c("JV (dense)", "SAP (sparse)", "LAPMOD (sparse)"), 3),
    levels = c("JV (dense)", "SAP (sparse)", "LAPMOD (sparse)")),
  size = rep(c(50, 100, 200), each = 3),
  time = c(
    # n=50
    0.0008, 0.0003, 0.0003,
    # n=100
    0.003, 0.0008, 0.0007,
    # n=200
    0.015, 0.002, 0.0018
  )
)
```

```{r sparse-plot, fig.width=7, fig.height=4, fig.alt="Sparse algorithm performance comparison"}
ggplot(sparse_results, aes(x = size, y = time * 1000, color = method, group = method)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3) +
  labs(
    title = "Sparse vs Dense Algorithms (80% Forbidden Entries)",
    x = "Matrix Size (n x n)",
    y = "Time (milliseconds)",
    color = "Algorithm"
  ) +
  scale_color_manual(values = c("#5bc0de", "#5cb85c", "#f0ad4e")) +
  theme_minimal() +
  theme(legend.position = "bottom", plot.title = element_text(face = "bold"))
```

**Takeaway**: For sparse problems, SAP and LAPMOD significantly outperform dense algorithms.

---

## Performance Summary

| Size | Hungarian | JV | Auction | SAP | CSA | Network Simplex | Orlin |
|------|-----------|----|---------|----|-----|-----------------|-------|
| < 100 | Excellent | Excellent | Good | Good | Good | Good | Good |
| 100-500 | Good | Excellent | Excellent | Excellent | Excellent | Good | Good |
| 500-2000 | Slow | Excellent | Excellent | Excellent | Excellent | Good | Good |
| > 2000 | Too slow | Good | Excellent | Excellent | Excellent | Good | Excellent |

**Notes:**

- SAP/LAPMOD: Best for sparse problems (>50% forbidden entries)
- HK01: Only for binary costs (0/1), then O(n^2.5)
- Gabow-Tarjan: Best for large integer cost ranges; O(n³ log C)
- Ramshaw-Tarjan: Best for rectangular problems (n ≠ m)
- Push-Relabel: Competitive for max-flow style problems

---

## References

- Kuhn, H. W. (1955). The Hungarian method for the assignment problem. *Naval Research Logistics Quarterly*.
- Jonker, R., & Volgenant, A. (1987). A shortest augmenting path algorithm for dense and sparse linear assignment problems. *Computing*.
- Bertsekas, D. P. (1988). The auction algorithm: A distributed relaxation method. *Annals of Operations Research*.
- Gabow, H. N., & Tarjan, R. E. (1989). Faster scaling algorithms for network problems. *SIAM Journal on Computing*, 18(5), 1013-1036.
- Goldberg, A. V., & Kennedy, R. (1995). An efficient cost scaling algorithm for the assignment problem. *Mathematical Programming*, 71(2), 153-177.
- Orlin, J. B., & Ahuja, R. K. (1992). New scaling algorithms for the assignment and minimum mean cycle problems. *Mathematical Programming*, 54(1), 41-56.
- Ramshaw, L., & Tarjan, R. E. (2012). On minimum-cost assignments in unbalanced bipartite graphs. *HP Labs Technical Report*.
- Goldberg, A. V., & Tarjan, R. E. (1988). A new approach to the maximum-flow problem. *Journal of the ACM*, 35(4), 921-940.
- Murty, K. G. (1968). An algorithm for ranking all assignments in order of increasing cost. *Operations Research*.
- Cuturi, M. (2013). Sinkhorn distances: Lightspeed computation of optimal transport. *NeurIPS*.
- Burkard, R., Dell'Amico, M., & Martello, S. (2009). *Assignment Problems*. SIAM.

---

## See Also

- `vignette("getting-started")` - Basic usage and quick start
- `vignette("matching-workflows")` - Production matching pipelines
- `vignette("comparison")` - How couplr compares to MatchIt, optmatch, designmatch
- `vignette("troubleshooting")` - Common issues and solutions
- `vignette("pixel-morphing")` - Large-scale approximation strategies
- `?assignment` - Core solver with all 20 methods
- `?lap_solve` - Tidy interface
- `?lap_solve_kbest` - K-best solutions
- `?assignment_duals` - Dual variable extraction
- `?bottleneck_assignment` - Minimax objective
- `?sinkhorn` - Entropy-regularized transport
